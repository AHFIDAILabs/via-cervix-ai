{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1488b551",
   "metadata": {},
   "source": [
    "### **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20aa938f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\09_AHFID\\\\via-cervix-ai\\\\notebook'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84df8887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\09_AHFID\\\\via-cervix-ai'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f7357",
   "metadata": {},
   "source": [
    "### **Import and Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e2974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\09_AHFID\\via-cervix-ai\\venv-ave\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Data directory: artifacts\\via-cervix\n",
      "Results directory: artifacts\\training_runs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFilter, ImageDraw, ImageEnhance\n",
    "import timm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = Path(\"artifacts\") / \"via-cervix\"\n",
    "RESULTS_DIR = Path(\"artifacts\") / \"training_runs\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLASS_NAMES = [\"Negative\", \"Positive\", \"Suspicious cancer\"]\n",
    "CLASS_TO_IDX = {c:i for i,c in enumerate(CLASS_NAMES)}\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9bb9b",
   "metadata": {},
   "source": [
    "### **Utilities for listing the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e63923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images_by_class(root_dir, class_names):\n",
    "    \"\"\"Load images from class folders\"\"\"\n",
    "    items = []\n",
    "    for cls in class_names:\n",
    "        folder = root_dir / cls\n",
    "        if not folder.exists():\n",
    "            print(f\"Warning: Missing folder: {folder}\")\n",
    "            continue\n",
    "        \n",
    "        count = 0\n",
    "        for p in folder.rglob(\"*\"):\n",
    "            if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                items.append((str(p), CLASS_TO_IDX[cls]))\n",
    "                count += 1\n",
    "        print(f\"Found {count} images in {cls} folder\")\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d324bf",
   "metadata": {},
   "source": [
    "### **Class imbalance handling strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c71791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance\"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss\n",
    "\n",
    "class CostSensitiveLoss(nn.Module):\n",
    "    \"\"\"Custom loss with heavy penalties for missing cancer cases\"\"\"\n",
    "    def __init__(self, cost_matrix):\n",
    "        super(CostSensitiveLoss, self).__init__()\n",
    "        self.cost_matrix = cost_matrix\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "        costs = self.cost_matrix[targets]\n",
    "        expected_costs = torch.sum(probs * costs, dim=1)\n",
    "        return expected_costs.mean()\n",
    "\n",
    "def create_cost_matrix(n_classes, cancer_penalty=15.0):\n",
    "    \"\"\"Create cost matrix where missing cancer is heavily penalized\"\"\"\n",
    "    cost_matrix = torch.ones(n_classes, n_classes)\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            if i != j:\n",
    "                cost_matrix[i, j] = 1.0\n",
    "            else:\n",
    "                cost_matrix[i, j] = 0.0\n",
    "    \n",
    "    # Heavy penalty for missing suspicious cancer (class 2)\n",
    "    cost_matrix[2, 0] = cancer_penalty  # suspicious -> negative\n",
    "    cost_matrix[2, 1] = cancer_penalty  # suspicious -> positive\n",
    "    \n",
    "    return cost_matrix\n",
    "\n",
    "class AggressiveAugmentation:\n",
    "    \"\"\"Aggressive augmentation for minority classes\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_realistic_artifacts(pil_img):\n",
    "        \"\"\"Add medical imaging artifacts\"\"\"\n",
    "        img = pil_img.copy()\n",
    "        \n",
    "        # Random brightness/contrast changes\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        img = enhancer.enhance(random.uniform(0.7, 1.3))\n",
    "        \n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        img = enhancer.enhance(random.uniform(0.8, 1.4))\n",
    "        \n",
    "        # Add specular highlights\n",
    "        if random.random() < 0.5:\n",
    "            img = AggressiveAugmentation.add_specular_highlights(img)\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_specular_highlights(pil_img, n_spots=None):\n",
    "        if n_spots is None:\n",
    "            n_spots = random.randint(1, 2)\n",
    "            \n",
    "        img = pil_img.convert(\"RGBA\")\n",
    "        w, h = img.size\n",
    "        \n",
    "        for _ in range(n_spots):\n",
    "            radius = int(min(w, h) * random.uniform(0.02, 0.12))\n",
    "            if radius < 2:\n",
    "                continue\n",
    "                \n",
    "            cx = random.randint(radius, max(radius+1, w - radius))\n",
    "            cy = random.randint(radius, max(radius+1, h - radius))\n",
    "            \n",
    "            highlight = Image.new('RGBA', (radius*2, radius*2), (0, 0, 0, 0))\n",
    "            draw = ImageDraw.Draw(highlight)\n",
    "            \n",
    "            for i in range(2):\n",
    "                r = max(1, radius - i * radius // 3)\n",
    "                alpha = int(255 * random.uniform(0.2, 0.5) * (1 - i/2))\n",
    "                draw.ellipse([radius-r, radius-r, radius+r, radius+r], \n",
    "                           fill=(255, 255, 255, alpha))\n",
    "            \n",
    "            img.paste(highlight, (cx-radius, cy-radius), highlight)\n",
    "        \n",
    "        return img.convert(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba1982",
   "metadata": {},
   "source": [
    "### **Transforms for minority class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378d84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced transforms\n",
    "minority_transforms = transforms.Compose([\n",
    "    transforms.Lambda(AggressiveAugmentation.add_realistic_artifacts),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.6),\n",
    "    transforms.RandomRotation(degrees=25),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "class ImbalancedDataset(Dataset):\n",
    "    \"\"\"Dataset with intelligent augmentation based on class frequency\"\"\"\n",
    "    def __init__(self, samples, val=False):\n",
    "        self.samples = samples\n",
    "        self.val = val\n",
    "        \n",
    "        if not val:\n",
    "            # Calculate augmentation factors\n",
    "            class_counts = Counter([label for _, label in samples])\n",
    "            max_count = max(class_counts.values()) if class_counts else 1\n",
    "            \n",
    "            self.augmentation_factor = {}\n",
    "            for class_id, count in class_counts.items():\n",
    "                self.augmentation_factor[class_id] = max(1, max_count // max(count, 1))\n",
    "            \n",
    "            print(f\"Augmentation factors: {self.augmentation_factor}\")\n",
    "            \n",
    "            # Expand dataset\n",
    "            self.expanded_samples = []\n",
    "            for path, label in samples:\n",
    "                self.expanded_samples.append((path, label))\n",
    "                # Add augmented versions for minority classes\n",
    "                for _ in range(self.augmentation_factor.get(label, 1) - 1):\n",
    "                    self.expanded_samples.append((path, label))\n",
    "        else:\n",
    "            self.expanded_samples = samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.expanded_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.expanded_samples[idx]\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            \n",
    "            if self.val:\n",
    "                # Standard validation transforms\n",
    "                transform = transforms.Compose([\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "                ])\n",
    "                img = transform(img)\n",
    "            else:\n",
    "                # Choose transforms based on class\n",
    "                if label == 2:  # Suspicious cancer - most aggressive\n",
    "                    img = minority_transforms(img)\n",
    "                elif label == 1:  # Positive - moderate augmentation\n",
    "                    transform = transforms.Compose([\n",
    "                        transforms.Resize((224, 224)),\n",
    "                        transforms.RandomHorizontalFlip(p=0.5),\n",
    "                        transforms.RandomRotation(degrees=15),\n",
    "                        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "                    ])\n",
    "                    img = transform(img)\n",
    "                else:  # Negative - light augmentation\n",
    "                    transform = transforms.Compose([\n",
    "                        transforms.Resize((224, 224)),\n",
    "                        transforms.RandomHorizontalFlip(p=0.3),\n",
    "                        transforms.RandomRotation(degrees=8),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "                    ])\n",
    "                    img = transform(img)\n",
    "            \n",
    "            return img, label, path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "            return torch.zeros(3, 224, 224), label, path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24388b02",
   "metadata": {},
   "source": [
    "### **Multi-stage training class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStageTrainer:\n",
    "    \"\"\"Multi-stage training to handle extreme imbalance\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device, class_names):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.class_names = class_names\n",
    "        \n",
    "    def _modify_classifier_output(self, num_classes):\n",
    "        \"\"\"Helper method to modify classifier output size\"\"\"\n",
    "        if hasattr(self.model, 'classifier'):\n",
    "            if isinstance(self.model.classifier, nn.Sequential):\n",
    "                # Find the last Linear layer in Sequential\n",
    "                layers = list(self.model.classifier.children())\n",
    "                for i in range(len(layers)-1, -1, -1):\n",
    "                    if isinstance(layers[i], nn.Linear):\n",
    "                        in_features = layers[i].in_features\n",
    "                        layers[i] = nn.Linear(in_features, num_classes)\n",
    "                        break\n",
    "                self.model.classifier = nn.Sequential(*layers)\n",
    "            else:\n",
    "                # Single Linear layer\n",
    "                in_features = self.model.classifier.in_features\n",
    "                self.model.classifier = nn.Linear(in_features, num_classes)\n",
    "        elif hasattr(self.model, 'head'):\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "        return self.model.to(self.device)\n",
    "        \n",
    "    def stage1_binary_training(self, train_loader, epochs=3):\n",
    "        \"\"\"Stage 1: Train binary classifier (cancer vs non-cancer)\"\"\"\n",
    "        print(\"Stage 1: Binary cancer detection training...\")\n",
    "        \n",
    "        # Modify final layer for binary classification\n",
    "        self.model = self._modify_classifier_output(2)\n",
    "        \n",
    "        # Binary focal loss with higher weight for cancer\n",
    "        alpha = torch.tensor([0.3, 0.7]).to(self.device)\n",
    "        criterion = FocalLoss(alpha=alpha, gamma=2.0)\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            for data, target, _ in train_loader:\n",
    "                data = data.to(self.device)\n",
    "                # Convert to binary labels (0: non-cancer, 1: cancer)\n",
    "                binary_target = (target == 2).long().to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = criterion(output, binary_target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                batch_count += 1\n",
    "            \n",
    "            avg_loss = total_loss / max(batch_count, 1)\n",
    "            print(f\"  Binary epoch {epoch+1}/{epochs}, loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    def stage2_multiclass_training(self, train_loader, val_loader, epochs=8):\n",
    "        \"\"\"Stage 2: Fine-tune for 3-class classification\"\"\"\n",
    "        print(\"Stage 2: Multi-class fine-tuning...\")\n",
    "        \n",
    "        # Restore 3-class head\n",
    "        self.model = self._modify_classifier_output(3)\n",
    "        \n",
    "        # Cost-sensitive loss with heavy penalty for missing cancer\n",
    "        cost_matrix = create_cost_matrix(3, cancer_penalty=15.0).to(self.device)\n",
    "        criterion = CostSensitiveLoss(cost_matrix)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "        \n",
    "        best_cancer_recall = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            for data, target, _ in train_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                batch_count += 1\n",
    "            \n",
    "            # Evaluate\n",
    "            report, cm = self.evaluate(val_loader)\n",
    "            cancer_recall = report.get('Suspicious cancer', {}).get('recall', 0)\n",
    "            \n",
    "            avg_loss = total_loss / max(batch_count, 1)\n",
    "            print(f\"  Epoch {epoch+1}/{epochs}, loss: {avg_loss:.4f}, cancer recall: {cancer_recall:.3f}\")\n",
    "            \n",
    "            if cancer_recall > best_cancer_recall:\n",
    "                best_cancer_recall = cancer_recall\n",
    "        \n",
    "        return best_cancer_recall\n",
    "    \n",
    "    def evaluate(self, val_loader):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        self.model.eval()\n",
    "        all_preds, all_targets = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target, _ in val_loader:\n",
    "                data = data.to(self.device)\n",
    "                output = self.model(data)\n",
    "                pred = output.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.extend(pred)\n",
    "                all_targets.extend(target.numpy())\n",
    "        \n",
    "        try:\n",
    "            report = classification_report(all_targets, all_preds, \n",
    "                                         target_names=self.class_names, \n",
    "                                         output_dict=True, zero_division=0)\n",
    "            cm = confusion_matrix(all_targets, all_preds, labels=[0,1,2])\n",
    "        except Exception as e:\n",
    "            print(f\"Error in evaluation: {e}\")\n",
    "            report = {'Suspicious cancer': {'recall': 0}}\n",
    "            cm = np.zeros((3,3))\n",
    "        \n",
    "        return report, cm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3610b",
   "metadata": {},
   "source": [
    "### **Model optimization for imbalanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc45fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_improved_model():\n",
    "    \"\"\"Create model optimized for imbalanced data\"\"\"\n",
    "    model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=3)\n",
    "    \n",
    "    # Add dropout for regularization\n",
    "    if hasattr(model, 'classifier'):\n",
    "        in_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def save_evaluation_files(model, val_loader, results_dir):\n",
    "    \"\"\"Save evaluation files for comprehensive evaluation notebook\"\"\"\n",
    "    print(\"Saving evaluation files...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_labels, all_probs = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target, _ in val_loader:\n",
    "            data = data.to(DEVICE)\n",
    "            logits = model(data)\n",
    "            probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "            \n",
    "            all_labels.extend(target.numpy())\n",
    "            all_probs.extend(probs)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    eval_labels = np.array(all_labels)\n",
    "    eval_probs = np.array(all_probs)\n",
    "    \n",
    "    # Save files\n",
    "    np.save(results_dir / \"eval_labels.npy\", eval_labels)\n",
    "    np.save(results_dir / \"eval_probs.npy\", eval_probs)\n",
    "    \n",
    "    print(f\"Saved evaluation files: {len(eval_labels)} samples\")\n",
    "    print(f\"  Labels shape: {eval_labels.shape}\")\n",
    "    print(f\"  Probabilities shape: {eval_probs.shape}\")\n",
    "    \n",
    "    # Verify files\n",
    "    try:\n",
    "        test_labels = np.load(results_dir / \"eval_labels.npy\")\n",
    "        test_probs = np.load(results_dir / \"eval_probs.npy\")\n",
    "        print(\"  Files verified successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  Error verifying files: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a7f004",
   "metadata": {},
   "source": [
    "### **Main training function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140a7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STARTING IMPROVED CLASS IMBALANCE TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        all_items = list_images_by_class(DATA_DIR, CLASS_NAMES)\n",
    "        if len(all_items) == 0:\n",
    "            print(f\"ERROR: No images found in {DATA_DIR}\")\n",
    "            print(\"Expected structure:\")\n",
    "            print(f\"  {DATA_DIR}/\")\n",
    "            print(\"    Negative/\")\n",
    "            print(\"    Positive/\")\n",
    "            print(\"    Suspicious cancer/\")\n",
    "            return None\n",
    "        \n",
    "        class_counts = Counter([y for _, y in all_items])\n",
    "        print(f\"Total images: {len(all_items)}\")\n",
    "        print(f\"Class distribution: {dict(class_counts)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare cross-validation\n",
    "    paths = [item[0] for item in all_items]\n",
    "    labels = [item[1] for item in all_items]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    fold_results = []\n",
    "    best_model = None\n",
    "    best_val_loader = None\n",
    "    best_recall = 0\n",
    "    \n",
    "    # Run cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(paths, labels), 1):\n",
    "        print(f\"\\nFOLD {fold}/5\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        train_samples = [(paths[i], labels[i]) for i in train_idx]\n",
    "        val_samples = [(paths[i], labels[i]) for i in val_idx]\n",
    "        \n",
    "        print(f\"Train samples: {len(train_samples)}\")\n",
    "        print(f\"Validation samples: {len(val_samples)}\")\n",
    "        \n",
    "        # Create datasets\n",
    "        train_ds = ImbalancedDataset(train_samples, val=False)\n",
    "        val_ds = ImbalancedDataset(val_samples, val=True)\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Create and train model\n",
    "        model = create_improved_model()\n",
    "        trainer = MultiStageTrainer(model, DEVICE, CLASS_NAMES)\n",
    "        \n",
    "        # Two-stage training\n",
    "        trainer.stage1_binary_training(train_loader, epochs=3)\n",
    "        cancer_recall = trainer.stage2_multiclass_training(train_loader, val_loader, epochs=6)\n",
    "        \n",
    "        fold_results.append(cancer_recall)\n",
    "        print(f\"Fold {fold} final cancer recall: {cancer_recall:.3f}\")\n",
    "        \n",
    "        # Track best model\n",
    "        if cancer_recall > best_recall:\n",
    "            best_recall = cancer_recall\n",
    "            best_model = model\n",
    "            best_val_loader = val_loader\n",
    "        \n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), RESULTS_DIR / f\"fold_{fold}_model.pth\")\n",
    "    \n",
    "    # Save evaluation files\n",
    "    print(f\"\\nSaving evaluation files using best model (recall: {best_recall:.3f})\")\n",
    "    if best_model is not None and save_evaluation_files(best_model, best_val_loader, RESULTS_DIR):\n",
    "        print(\"Evaluation files saved successfully\")\n",
    "    else:\n",
    "        print(\"Failed to save evaluation files\")\n",
    "    \n",
    "    # Save summary\n",
    "    cv_summary = {\n",
    "        \"n_folds\": 5,\n",
    "        \"cancer_recall_mean\": float(np.mean(fold_results)),\n",
    "        \"cancer_recall_std\": float(np.std(fold_results)),\n",
    "        \"best_recall\": float(best_recall),\n",
    "        \"fold_results\": [float(x) for x in fold_results]\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_DIR / \"cv_summary.json\", 'w') as f:\n",
    "        json.dump(cv_summary, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING COMPLETED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Cancer recall: {np.mean(fold_results):.3f} ± {np.std(fold_results):.3f}\")\n",
    "    print(f\"Best fold recall: {best_recall:.3f}\")\n",
    "    print(f\"Files saved to: {RESULTS_DIR}\")\n",
    "    print(\"\\nFiles created:\")\n",
    "    print(\"- fold_*_model.pth (model checkpoints)\")\n",
    "    print(\"- eval_labels.npy (for evaluation notebook)\")\n",
    "    print(\"- eval_probs.npy (for evaluation notebook)\")\n",
    "    print(\"- cv_summary.json (training summary)\")\n",
    "    \n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7042107a",
   "metadata": {},
   "source": [
    "### **Execute training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4045f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory found: artifacts\\via-cervix\n",
      "============================================================\n",
      "STARTING IMPROVED CLASS IMBALANCE TRAINING\n",
      "============================================================\n",
      "Found 92 images in Negative folder\n",
      "Found 78 images in Positive folder\n",
      "Found 20 images in Suspicious cancer folder\n",
      "Total images: 190\n",
      "Class distribution: {0: 92, 1: 78, 2: 20}\n",
      "\n",
      "FOLD 1/5\n",
      "------------------------------\n",
      "Train samples: 152\n",
      "Validation samples: 38\n",
      "Augmentation factors: {0: 1, 1: 1, 2: 4}\n",
      "Stage 1: Binary cancer detection training...\n",
      "  Binary epoch 1/3, loss: 0.0273\n",
      "  Binary epoch 2/3, loss: 0.0222\n",
      "  Binary epoch 3/3, loss: 0.0193\n",
      "Stage 2: Multi-class fine-tuning...\n",
      "  Epoch 1/6, loss: 3.5570, cancer recall: 0.250\n",
      "  Epoch 2/6, loss: 3.4318, cancer recall: 0.500\n",
      "  Epoch 3/6, loss: 3.2414, cancer recall: 0.750\n",
      "  Epoch 4/6, loss: 3.1092, cancer recall: 0.750\n",
      "  Epoch 5/6, loss: 2.8208, cancer recall: 0.750\n",
      "  Epoch 6/6, loss: 2.4976, cancer recall: 0.750\n",
      "Fold 1 final cancer recall: 0.750\n",
      "\n",
      "FOLD 2/5\n",
      "------------------------------\n",
      "Train samples: 152\n",
      "Validation samples: 38\n",
      "Augmentation factors: {0: 1, 1: 1, 2: 4}\n",
      "Stage 1: Binary cancer detection training...\n",
      "  Binary epoch 1/3, loss: 0.0266\n",
      "  Binary epoch 2/3, loss: 0.0232\n",
      "  Binary epoch 3/3, loss: 0.0216\n",
      "Stage 2: Multi-class fine-tuning...\n",
      "  Epoch 1/6, loss: 3.7604, cancer recall: 0.250\n",
      "  Epoch 2/6, loss: 3.6429, cancer recall: 0.250\n",
      "  Epoch 3/6, loss: 3.5566, cancer recall: 0.250\n",
      "  Epoch 4/6, loss: 3.4445, cancer recall: 0.500\n",
      "  Epoch 5/6, loss: 3.3282, cancer recall: 0.750\n",
      "  Epoch 6/6, loss: 3.1352, cancer recall: 1.000\n",
      "Fold 2 final cancer recall: 1.000\n",
      "\n",
      "FOLD 3/5\n",
      "------------------------------\n",
      "Train samples: 152\n",
      "Validation samples: 38\n",
      "Augmentation factors: {0: 1, 1: 1, 2: 4}\n",
      "Stage 1: Binary cancer detection training...\n",
      "  Binary epoch 1/3, loss: 0.0223\n",
      "  Binary epoch 2/3, loss: 0.0207\n",
      "  Binary epoch 3/3, loss: 0.0183\n",
      "Stage 2: Multi-class fine-tuning...\n",
      "  Epoch 1/6, loss: 3.4856, cancer recall: 0.750\n",
      "  Epoch 2/6, loss: 3.2922, cancer recall: 1.000\n",
      "  Epoch 3/6, loss: 3.1184, cancer recall: 1.000\n",
      "  Epoch 4/6, loss: 2.9096, cancer recall: 1.000\n",
      "  Epoch 5/6, loss: 2.6156, cancer recall: 1.000\n",
      "  Epoch 6/6, loss: 2.2783, cancer recall: 1.000\n",
      "Fold 3 final cancer recall: 1.000\n",
      "\n",
      "FOLD 4/5\n",
      "------------------------------\n",
      "Train samples: 152\n",
      "Validation samples: 38\n",
      "Augmentation factors: {0: 1, 1: 1, 2: 4}\n",
      "Stage 1: Binary cancer detection training...\n",
      "  Binary epoch 1/3, loss: 0.0275\n",
      "  Binary epoch 2/3, loss: 0.0237\n",
      "  Binary epoch 3/3, loss: 0.0212\n",
      "Stage 2: Multi-class fine-tuning...\n",
      "  Epoch 1/6, loss: 3.7205, cancer recall: 0.000\n",
      "  Epoch 2/6, loss: 3.6658, cancer recall: 0.000\n",
      "  Epoch 3/6, loss: 3.5930, cancer recall: 0.000\n",
      "  Epoch 4/6, loss: 3.4681, cancer recall: 0.250\n",
      "  Epoch 5/6, loss: 3.3814, cancer recall: 0.250\n",
      "  Epoch 6/6, loss: 3.2879, cancer recall: 1.000\n",
      "Fold 4 final cancer recall: 1.000\n",
      "\n",
      "FOLD 5/5\n",
      "------------------------------\n",
      "Train samples: 152\n",
      "Validation samples: 38\n",
      "Augmentation factors: {0: 1, 1: 1, 2: 4}\n",
      "Stage 1: Binary cancer detection training...\n",
      "  Binary epoch 1/3, loss: 0.0332\n",
      "  Binary epoch 2/3, loss: 0.0248\n",
      "  Binary epoch 3/3, loss: 0.0223\n",
      "Stage 2: Multi-class fine-tuning...\n",
      "  Epoch 1/6, loss: 3.6709, cancer recall: 0.750\n",
      "  Epoch 2/6, loss: 3.6053, cancer recall: 1.000\n",
      "  Epoch 3/6, loss: 3.4606, cancer recall: 1.000\n",
      "  Epoch 4/6, loss: 3.3605, cancer recall: 1.000\n",
      "  Epoch 5/6, loss: 3.1593, cancer recall: 1.000\n",
      "  Epoch 6/6, loss: 2.8836, cancer recall: 1.000\n",
      "Fold 5 final cancer recall: 1.000\n",
      "\n",
      "Saving evaluation files using best model (recall: 1.000)\n",
      "Saving evaluation files...\n",
      "Saved evaluation files: 38 samples\n",
      "  Labels shape: (38,)\n",
      "  Probabilities shape: (38, 3)\n",
      "  Files verified successfully\n",
      "Evaluation files saved successfully\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Cancer recall: 0.950 ± 0.100\n",
      "Best fold recall: 1.000\n",
      "Files saved to: artifacts\\training_runs\n",
      "\n",
      "Files created:\n",
      "- fold_*_model.pth (model checkpoints)\n",
      "- eval_labels.npy (for evaluation notebook)\n",
      "- eval_probs.npy (for evaluation notebook)\n",
      "- cv_summary.json (training summary)\n"
     ]
    }
   ],
   "source": [
    "# Execute training\n",
    "if DATA_DIR.exists():\n",
    "    print(f\"Data directory found: {DATA_DIR}\")\n",
    "    results = run_training()\n",
    "else:\n",
    "    print(f\"Data directory not found: {DATA_DIR}\")\n",
    "    print(\"Please ensure your data is in the correct location.\")\n",
    "    results = None"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
